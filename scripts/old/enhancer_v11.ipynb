{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67d9660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import sqlite3\n",
    "import subprocess\n",
    "import webbrowser\n",
    "from collections import Counter\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, ttk, Canvas\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "import torch\n",
    "import faiss\n",
    "import heapq\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import logging\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import logging as transformers_logging\n",
    "from keybert import KeyBERT\n",
    "import pyperclip\n",
    "\n",
    "# === INITIALISATION ===\n",
    "\n",
    "# Chargement des variables de configuration\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "config_path = os.path.join(PROJECT_ROOT, \"config.json\")\n",
    "\n",
    "def expand_path(value):\n",
    "    expanded = os.path.expanduser(value)\n",
    "    if not os.path.isabs(expanded):\n",
    "        expanded = os.path.normpath(os.path.join(PROJECT_ROOT, expanded))\n",
    "    return expanded\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_config = json.load(f)\n",
    "\n",
    "    path_keys = {\n",
    "        \"venv_activate_path\",\n",
    "        \"lmstudio_folder_path\",\n",
    "        \"sync_script_path\",\n",
    "        \"project_script_path\",\n",
    "        \"db_path\",\n",
    "        \"stopwords_file_path\"\n",
    "    }\n",
    "\n",
    "    config = {}\n",
    "    for key, value in raw_config.items():\n",
    "        if isinstance(value, str):\n",
    "            if key == \"summarizing_model\" and value == \"model/barthez-orangesum-abstract\":\n",
    "                config[key] = expand_path(value)\n",
    "            elif key in path_keys:\n",
    "                config[key] = expand_path(value)\n",
    "            else:\n",
    "                config[key] = value\n",
    "        else:\n",
    "            config[key] = value\n",
    "    return config\n",
    "\n",
    "config = load_config(config_path)\n",
    "\n",
    "stopwords_path = config.get(\"stopwords_file_path\", \"stopwords_fr.json\")\n",
    "with open(stopwords_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    french_stop_words = set(json.load(f))\n",
    "\n",
    "combined_stopwords = ENGLISH_STOP_WORDS.union(french_stop_words)\n",
    "\n",
    "# Masquage des avertissements\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "#logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "#logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
    "#torch._C._log_api_usage_once = lambda *args, **kwargs: None\n",
    "#warnings.filterwarnings(\"ignore\", message=\"Unfeasible length constraints\", category=UserWarning, module=\"transformers.generation.utils\")\n",
    "\n",
    "# Connexion à la base SQLite\n",
    "conn = sqlite3.connect(config[\"db_path\"])\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Initialisation des modèles\n",
    "nlp_fr = spacy.load(\"fr_core_news_lg\")\n",
    "nlp_en = spacy.load(\"en_core_web_lg\")\n",
    "kw_model = KeyBERT()\n",
    "summarizing_model = config.get(\"summarizing_model\", \"model/barthez-orangesum-abstract\")\n",
    "summarizing_pipeline = pipeline(task=\"summarization\", model=summarizing_model, framework=\"pt\")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Index vectoriel\n",
    "VECTOR_DIM = 384\n",
    "faiss_index = faiss.IndexFlatL2(VECTOR_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7be31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FONCTIONS PRINCIPALES ===\n",
    "\n",
    "# Synchronisation des conversations\n",
    "def sync_conversations(config, label_status):\n",
    "    sync_path = config.get(\"sync_script_path\")\n",
    "    if not sync_path:\n",
    "        label_status.config(text=\"sync_script_path introuvable.\")\n",
    "        return False\n",
    "    try:\n",
    "        subprocess.run([\"python3\", sync_path], check=True)\n",
    "        label_status.config(text=\"Synchronisation terminée.\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError:\n",
    "        label_status.config(text=\"Erreur lors de la synchronisation.\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        label_status.config(text=\"Script de synchronisation introuvable.\")\n",
    "        return False\n",
    "\n",
    "# Pércuteur\n",
    "def on_ask():\n",
    "    question = entry_question.get(\"1.0\", \"end-1c\")\n",
    "    if not question.strip():\n",
    "        update_status(\"⚠️ Merci de saisir une question.\", error=True)\n",
    "        return\n",
    "    update_status(\"⚙️ Traitement en cours...\")\n",
    "    root.update()\n",
    "    try:\n",
    "        context = get_relevant_context(question, limit=context_count_var.get()) #\", limit=context_count_var.get()\" ajoutée slider contexte\n",
    "        prompt = generate_prompt_paragraph(context, question)\n",
    "        pyperclip.copy(prompt)\n",
    "        text_output.delete('1.0', tk.END)\n",
    "        text_output.insert(tk.END, prompt)\n",
    "        \n",
    "        # Calcul des métriques\n",
    "        context_count = len(context)\n",
    "        token_count = len(prompt.split())\n",
    "        \n",
    "        update_status(\n",
    "            f\"Prompt généré ({token_count} tokens) | Contexte utilisé : {context_count} éléments\",\n",
    "            success=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        update_status(f\"❌ Erreur : {str(e)}\", error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7036ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONTEXTE ===\n",
    "\n",
    "# Choix NLP selon langue\n",
    "def get_nlp_model(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except:\n",
    "        lang = \"fr\"  # défaut français si détection impossible\n",
    "    \n",
    "    if lang.startswith(\"en\"):\n",
    "        return nlp_en\n",
    "    else:\n",
    "        return nlp_fr\n",
    "\n",
    "\n",
    "# Récupération des mots-clés de la question initiale\n",
    "root = tk.Tk()\n",
    "keyword_count_var = tk.IntVar(value=5)\n",
    "context_count_var = tk.IntVar(value=3)\n",
    "multiplier = config.get(\"keyword_multiplier\", 2)\n",
    "\n",
    "def extract_keywords(text, top_n=None):\n",
    "    if top_n is None:\n",
    "        top_n = keyword_count_var.get()\n",
    "\n",
    "    # Extraction brute avec KeyBERT\n",
    "    raw_keywords = kw_model.extract_keywords(\n",
    "        text,\n",
    "        keyphrase_ngram_range=(1, 1),\n",
    "        stop_words=list(combined_stopwords),\n",
    "        top_n=top_n * multiplier)\n",
    "\n",
    "    stopwords_set = set(combined_stopwords)\n",
    "\n",
    "    tokens = re.findall(r'\\b[a-zA-Z\\-]{3,}\\b', text.lower())\n",
    "    token_freq = Counter([tok for tok in tokens if tok not in stopwords_set])\n",
    "\n",
    "    # Fonction de validation rapide des mots clés\n",
    "    def is_valid_kw(kw):\n",
    "        return (\n",
    "            kw not in stopwords_set and\n",
    "            len(kw) > 2 and\n",
    "            kw.isalpha() or '-' in kw\n",
    "        )\n",
    "\n",
    "    # Tri par fréquence dans le texte #  /!\\ ==peu entrainer des doublons== /!\\\n",
    "    filtered_raw = []\n",
    "    for kw, weight in raw_keywords:\n",
    "        kw_clean = kw.lower().strip()\n",
    "        if is_valid_kw(kw_clean):\n",
    "            freq = token_freq.get(kw_clean, 0)\n",
    "            filtered_raw.append((freq, kw_clean, weight))\n",
    "\n",
    "    top_filtered = heapq.nlargest(top_n, filtered_raw, key=lambda x: x[0])\n",
    "\n",
    "    seen = set()\n",
    "    filtered_keywords = []\n",
    "    for freq, kw_clean, weight in top_filtered:\n",
    "        if kw_clean not in seen:\n",
    "            seen.add(kw_clean)\n",
    "            filtered_keywords.append((kw_clean, weight, freq))\n",
    "\n",
    "    return filtered_keywords\n",
    "\n",
    "def get_vector_for_text(text):\n",
    "    print(f\"Type de embedding_model : {type(embedding_model)}\")\n",
    "    print(f\"embedding_model : {embedding_model}\")\n",
    "    print(f\"Is instance of SentenceTransformer? {isinstance(embedding_model, SentenceTransformer)}\")\n",
    "\n",
    "    vec = embedding_model.encode([text])\n",
    "    return np.array(vec[0], dtype='float32')\n",
    "\n",
    "# Récupération des anciennes conversations pertinentes\n",
    "\n",
    "def get_relevant_context(user_question, limit=None):\n",
    "    if limit is None:\n",
    "        limit = context_count_var.get()\n",
    "\n",
    "    keywords = extract_keywords(user_question)\n",
    "    if not keywords or not isinstance(keywords, (list, tuple)):\n",
    "        print(\"Warning: keywords non valides ou vides:\", keywords)\n",
    "        return []\n",
    "\n",
    "    # S’assurer que keywords est une liste de tuples (keyword, score) ou similaire\n",
    "    try:\n",
    "        keyword_strings = [kw[0] for kw in keywords if isinstance(kw, (list, tuple)) and len(kw) > 0]\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur extraction keywords: {e}\")\n",
    "        return []\n",
    "\n",
    "    if not keyword_strings:\n",
    "        print(\"Warning: liste keyword_strings vide après extraction\")\n",
    "        return []\n",
    "\n",
    "    placeholders = ', '.join(['?'] * len(keyword_strings))\n",
    "\n",
    "    # 1. Récupérer les conversations + vecteurs filtrés par mots-clés\n",
    "    query_vectors = f'''\n",
    "        SELECT conversation_id, vector\n",
    "        FROM vectors\n",
    "        WHERE keyword IN ({placeholders})\n",
    "    '''\n",
    "    cur.execute(query_vectors, keyword_strings)\n",
    "    vector_rows = cur.fetchall()  # [(conversation_id, vector_str), ...]\n",
    "\n",
    "    if not vector_rows:\n",
    "        return []\n",
    "\n",
    "    convo_ids = []\n",
    "    vectors = []\n",
    "\n",
    "    # Convertir les vecteurs string en numpy array\n",
    "    for convo_id, vec_str in vector_rows:\n",
    "        print(f\"Vecteur brut convo {convo_id}:\", repr(vec_str))\n",
    "        if not vec_str or not vec_str.strip():\n",
    "            print(f\"Attention: vecteur vide pour conversation {convo_id}\")\n",
    "            continue\n",
    "        try:\n",
    "            vec_str_clean = vec_str.strip().replace('\\n', '').replace('\\r', '').replace('[', '').replace(']', '')\n",
    "            vec = np.fromstring(vec_str_clean, sep=',').astype('float32')\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur conversion vecteur pour convo {convo_id}: {e}\")\n",
    "            continue\n",
    "        convo_ids.append(convo_id)\n",
    "        vectors.append(vec)\n",
    "\n",
    "    if not vectors:\n",
    "        return []\n",
    "\n",
    "    vectors = np.array(vectors).astype('float32')\n",
    "\n",
    "    # Normalisation des vecteurs pour cosine similarity\n",
    "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    vectors = vectors / np.clip(norms, a_min=1e-10, a_max=None)  # éviter division par 0\n",
    "\n",
    "    # Construire l'index FAISS pour Inner Product (cosine similarity)\n",
    "    faiss_index = faiss.IndexFlatIP(vectors.shape[1])\n",
    "    faiss_index.add(vectors)\n",
    "\n",
    "    # Vecteur de la question\n",
    "    question_vec = get_vector_for_text(user_question).astype('float32').reshape(1, -1)\n",
    "\n",
    "    # Normaliser le vecteur question aussi\n",
    "    question_norm = np.linalg.norm(question_vec, axis=1, keepdims=True)\n",
    "    question_vec = question_vec / np.clip(question_norm, a_min=1e-10, a_max=None)\n",
    "\n",
    "    # Recherche des k voisins les plus proches (cosine similarity)\n",
    "    distances, indices = faiss_index.search(question_vec, limit)\n",
    "\n",
    "    # Récupérer les convo_ids correspondants\n",
    "    found_convo_ids = [convo_ids[idx] for idx in indices[0] if idx != -1]\n",
    "\n",
    "    if not found_convo_ids:\n",
    "        return []\n",
    "\n",
    "    placeholders_ids = ', '.join(['?'] * len(found_convo_ids))\n",
    "\n",
    "    # Récupérer les conversations\n",
    "    query_contexts = f'''\n",
    "        SELECT id, user_input, llm_output, timestamp\n",
    "        FROM conversations\n",
    "        WHERE id IN ({placeholders_ids})\n",
    "    '''\n",
    "    cur.execute(query_contexts, found_convo_ids)\n",
    "    context_rows = cur.fetchall()\n",
    "\n",
    "    # Récupérer les mots-clés associés\n",
    "    query_keywords = f'''\n",
    "    SELECT conversation_id, keyword\n",
    "    FROM vectors\n",
    "    WHERE conversation_id IN ({placeholders_ids})\n",
    "    '''\n",
    "    cur.execute(query_keywords, found_convo_ids)\n",
    "    keyword_rows = cur.fetchall()\n",
    "\n",
    "    print(\"keyword_rows (after fetch):\", keyword_rows)\n",
    "\n",
    "    # Test plus sûr sur les données\n",
    "    keywords_by_convo = {}\n",
    "    for row in keyword_rows:\n",
    "        if isinstance(row, (list, tuple)):\n",
    "            if len(row) == 2:\n",
    "                convo_id, keyword = row\n",
    "                keywords_by_convo.setdefault(convo_id, set()).add(keyword)\n",
    "            else:\n",
    "                print(f\"Unexpected row length: {row}\")\n",
    "        else:\n",
    "            print(f\"Unexpected row type (expect tuple/list): {type(row)} - value: {row}\")\n",
    "\n",
    "\n",
    "    # Construire le résultat final avec les scores de similarité\n",
    "    filtered_context = []\n",
    "    for idx, (convo_id, user_input, llm_output, timestamp) in enumerate(context_rows):\n",
    "        kws = list(keywords_by_convo.get(convo_id, []))\n",
    "        score = distances[0][idx] if idx < len(distances[0]) else 0.0  # sécuriser accès score\n",
    "        filtered_context.append((user_input, llm_output, timestamp, kws, score))\n",
    "\n",
    "    return filtered_context\n",
    "\n",
    "\n",
    "\n",
    "# Nettoyage du texte\n",
    "def nlp_clean_text(text, max_chunk_size=500):\n",
    "    text = re.sub(r'```(?:python)?\\s*.*?```', '', text, flags=re.DOTALL)\n",
    "    nlp = get_nlp_model(text)\n",
    "    chunks, current_chunk, current_length = [], [], 0\n",
    "\n",
    "    for sent in nlp(text).sents:\n",
    "        s = sent.text.strip()\n",
    "        if len(s) < 20:\n",
    "            continue\n",
    "        if current_length + len(s) < max_chunk_size:\n",
    "            current_chunk.append(s)\n",
    "            current_length += len(s)\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [s]\n",
    "            current_length = len(s)\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return \" \".join(chunks[:3])  # limite à 3 blocs maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c5769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONSTRUCTION DU PROMPT ===\n",
    "\n",
    "# Compression du contexte extrait\n",
    "def summarize(text, focus_terms=None, max_length=1024):\n",
    "    transformers_logging.set_verbosity_error()\n",
    "    try:\n",
    "        # Filtrage des phrases importantes si focus_terms donné\n",
    "        if focus_terms:\n",
    "            sentences = [s for s in text.split('.') \n",
    "                        if any(term.lower() in s.lower() for term in focus_terms)]\n",
    "            text = '. '.join(sentences)[:2000] or text[:2000]\n",
    "\n",
    "        # Résumé avec le texte filtré\n",
    "        result = summarizing_pipeline(\n",
    "            text,\n",
    "            max_length=max_length,\n",
    "            min_length=max_length // 2,\n",
    "            no_repeat_ngram_size=3,\n",
    "            do_sample=False,\n",
    "            truncation=True\n",
    "        )\n",
    "        return nlp_clean_text(result[0]['summary_text'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur summarization : {e}\")\n",
    "        return text[:max_length] + \"... [résumé tronqué]\"\n",
    "    \n",
    "# Construction du prompt\n",
    "def generate_prompt_paragraph(context, question, target_tokens=1000):\n",
    "    if not context:\n",
    "        return f\"{question}\"\n",
    "\n",
    "    # 1. Prétraitement\n",
    "    processed_items = []\n",
    "    for item in context[:3]:  # Nombre max d'éléments dans le contexte\n",
    "        try:\n",
    "            # Extraction sécurisée\n",
    "            user_input = str(item[0])[:300]  # Troncature des questions longues\n",
    "            llm_output = str(item[1])\n",
    "            keyword = str(item[5]) if len(item) > 5 and str(item[3]).strip() not in {\"\", \"none\", \"null\", \"1\", \"2\", \"3\"} else None\n",
    "\n",
    "            # Summarization, netooyage, segmentation\n",
    "            summary = nlp_clean_text(summarize(llm_output))\n",
    "            processed_items.append({\n",
    "                'question': user_input,\n",
    "                'summary': summary,\n",
    "                'keyword': keyword if keyword else None\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur traitement item : {e}\")\n",
    "            continue\n",
    "\n",
    "    if not processed_items:\n",
    "        return question\n",
    "\n",
    "    # 2. Construction du prompt\n",
    "    parts = []\n",
    "\n",
    "    # Partie questions\n",
    "    if processed_items:\n",
    "        questions = [f\"'{item['question']}'\" for item in processed_items]\n",
    "        if len(questions) == 1:\n",
    "            parts.append(f\"Tes discussions avec l'utilisateur t'ont amené à répondre à cette question : {questions[0]}\")\n",
    "        else:\n",
    "            *init, last = questions\n",
    "            parts.append(f\"Tes discussions avec l'utilisateur t'ont amené à répondre à ces questions :  {', '.join(init)}, et enfin {last}\")\n",
    "\n",
    "    # Partie mots-clés\n",
    "    keywords = {item['keyword'] for item in processed_items if item['keyword']}\n",
    "    if keywords:\n",
    "        parts.append(f\"Mots-clés pertinents : {', '.join(sorted(keywords))}\")\n",
    "\n",
    "    # Partie résumés\n",
    "    if processed_items:\n",
    "        summaries = [f\"- {item['summary']}\" for item in processed_items]\n",
    "        parts.append(\"Ces intéractions vous ont amené à discuter de ces sujets :\\n\" + \"\\n\".join(summaries))\n",
    "\n",
    "    # Question actuelle\n",
    "    parts.append(f\"Réponds maintenant à cette question, dans le contexte de vos discussions précédentes : {question}\")\n",
    "\n",
    "    return \"\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62681f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecteur brut convo 42: '[-0.03203989565372467, 0.007134939078241587, -0.07414238899946213, -0.04461883753538132, -0.11072579026222229, -0.006147498730570078, 0.0804787278175354, 0.10960470885038376, 0.014741298742592335, -0.045208513736724854, -0.005541444756090641, -0.02903510071337223, 0.045439448207616806, 0.045019082725048065, -0.07905307412147522, -0.0662766695022583, 0.029352720826864243, -0.003597831819206476, 0.05020849034190178, 0.036834850907325745, -0.08112623542547226, 0.06656025350093842, 0.03899535909295082, 0.06608276069164276, -0.04336779564619064, 0.06670437753200531, -0.041366688907146454, 0.015143846161663532, -0.05393824353814125, -0.06567473709583282, 0.07326257228851318, 0.05076780170202255, 0.046099547296762466, -0.023754771798849106, 0.03979028761386871, 0.029361233115196228, -0.07884436845779419, 0.04738137871026993, 0.05724068358540535, 0.06068364530801773, -0.024577254429459572, -0.0722459927201271, -0.03671948239207268, 0.003274217713624239, 0.07636512070894241, -0.09647203236818314, -0.07283058017492294, 0.05799071863293648, 0.07589763402938843, 0.10965991020202637, -0.11427140980958939, -0.059908926486968994, -0.07668715715408325, 0.07201975584030151, -0.0028495758306235075, 0.00045244197826832533, -0.047076545655727386, 0.012583968229591846, -0.02558932639658451, 0.024259300902485847, -0.04774235934019089, 0.07175073772668839, 0.02802899107336998, 0.06042938679456711, 0.029582642018795013, 0.008473475463688374, 0.06096995249390602, 0.02228964865207672, 0.06930212676525116, -0.060379792004823685, -0.021765096113085747, -0.07803570479154587, 0.026047732681035995, 0.06261099874973297, 0.0019823138136416674, -0.03703821450471878, -0.011301557533442974, 0.016580231487751007, -0.028478818014264107, -0.03332590311765671, 0.11081192642450333, -0.060190070420503616, -0.12513339519500732, 0.0772119015455246, 0.0027149650268256664, -0.007618481293320656, 0.026614999398589134, -0.02773945964872837, 0.04666591063141823, -0.03229998052120209, 0.040936000645160675, 0.03054095432162285, -0.024233588948845863, -0.06239162012934685, -0.073630690574646, -0.022508032619953156, -0.06704042851924896, 0.025023210793733597, -0.03586852550506592, 0.07150890678167343, -0.011397366411983967, -0.02584790624678135, -0.09985269606113434, -0.061114367097616196, -0.022122986614704132, -0.027267806231975555, 0.028208807110786438, -0.08558161556720734, -0.0038088709115982056, 0.018624212592840195, -0.04846150055527687, 0.024351343512535095, -0.026720628142356873, -0.0024179224856197834, 0.03190448507666588, 0.09851434081792831, 0.046948883682489395, -0.0450906902551651, 0.06859090179204941, -0.04038168489933014, -0.0327531099319458, 0.00377795472741127, 0.0038031586445868015, -0.0693502426147461, -0.0072019281797111034, -0.01547653041779995, 0.06621269136667252, -1.703091572137351e-34, -0.012748247012495995, -0.012997481040656567, 0.10581280291080475, 0.10389628261327744, 0.025451434776186943, 0.0313398651778698, 0.00990210846066475, -0.0030693700537085533, -0.0554296113550663, -0.03499741852283478, -0.0689491406083107, 0.037641726434230804, -0.05954263359308243, 0.08223724365234375, 0.05437183752655983, 0.010907972231507301, -0.026425886899232864, 0.04870689660310745, 0.029660029336810112, -0.02793460339307785, 0.022307705134153366, 0.04603426530957222, -0.048321861773729324, 0.08420567959547043, -0.016392545774579048, 0.11528997868299484, -0.021129103377461433, 0.024779869243502617, 0.06931757181882858, 0.025099100545048714, 0.053332630544900894, 0.012869996950030327, -0.037093836814165115, -0.020661301910877228, -0.08118321001529694, -0.04334436357021332, -0.043227825313806534, -0.06179993227124214, 0.0476103350520134, -0.02430264838039875, -0.0316576212644577, 0.001327698933891952, 0.0002987985499203205, 0.008566683158278465, 0.05949091166257858, 0.022971879690885544, -0.08606229722499847, 0.016079062595963478, -0.06140456721186638, 0.040024466812610626, 0.024634618312120438, -0.04806751012802124, 0.07934337109327316, 0.02882610820233822, -0.11296764761209488, 0.05583690479397774, -0.06460855156183243, 0.012955619022250175, 0.041816018521785736, 0.03547017648816109, 0.07747840136289597, 0.11087637394666672, -0.05333175137639046, -0.022832484915852547, -0.010645751841366291, -0.014248416759073734, -0.06126352772116661, -0.01585937663912773, 0.01867113821208477, 0.04242327809333801, -0.08804096281528473, 0.01358038280159235, 0.057090725749731064, 0.09390035271644592, 0.0551188662648201, 0.01454166229814291, -0.07597357779741287, 0.028662631288170815, -0.02403099089860916, -0.018128223717212677, -0.08070839196443558, -0.06316693872213364, 0.02042464353144169, 0.11148804426193237, 0.03452777862548828, 0.013181043788790703, 0.0729837641119957, -0.023053161799907684, -0.024556275457143784, -0.00970157515257597, -0.11482420563697815, -0.009082013741135597, -0.036526381969451904, 0.0581059530377388, -0.0014954045182093978, -1.9212147426725e-33, 0.12691277265548706, -0.06254734843969345, -0.005260125268250704, 0.034011442214250565, 0.019771447405219078, -0.01903957687318325, -0.0016057869652286172, 0.0662500262260437, 0.052787501364946365, 0.03427010402083397, 0.013300898484885693, -0.028809620067477226, 0.1111905500292778, -0.05870363116264343, -0.0014058818342164159, 0.0035781096667051315, 0.04997941851615906, -0.04158201813697815, -0.08831434696912766, 0.030118312686681747, -0.02154233306646347, -0.06140211224555969, 0.05121986195445061, 0.026227382943034172, 0.009484685026109219, -0.006861072964966297, 0.10843676328659058, -0.03837522491812706, -0.026105158030986786, 0.04831083491444588, -0.029834356158971786, 0.018685676157474518, -0.07668668031692505, -0.024571513757109642, -0.1228654757142067, 0.04094621166586876, -0.019820064306259155, -0.0659487172961235, -0.029887456446886063, 0.002276233397424221, 0.025058316066861153, -0.041911132633686066, -0.04714086279273033, 0.05454004183411598, 0.0352494940161705, 0.012197566218674183, -0.06706162542104721, -0.0026177437976002693, 0.04149176552891731, -0.028066912665963173, 0.012147201225161552, 0.10631965845823288, 0.06655522435903549, 0.016800444573163986, 0.05361447483301163, -0.0052388450130820274, -0.04019343480467796, -0.06895438581705093, -0.019529839977622032, 0.0013890342088416219, 0.0363108329474926, 0.05794411897659302, -0.07460623979568481, -0.05314519628882408, 0.052098024636507034, 0.0035425741225481033, -0.02314050681889057, 0.023205367848277092, 0.008961423300206661, -0.03804311528801918, 0.10693594068288803, -0.0388210229575634, -0.003964253701269627, -0.00417275121435523, -0.05577116459608078, 0.005261292681097984, -0.038557905703783035, -0.06681520491838455, -0.016412576660513878, 0.01900244504213333, 0.03400395065546036, -0.11937510967254639, -0.04830925166606903, 0.09674558788537979, -0.059780266135931015, -0.02827061153948307, 0.03444572538137436, -0.027309754863381386, -0.011519933119416237, -0.013611149042844772, -0.03144575282931328, 0.03928833454847336, -0.07019545882940292, -0.004726432729512453, -0.0278928279876709, -1.734077770265685e-08, 0.07304005324840546, -0.033502738922834396, 0.09658011049032211, 0.04102618992328644, 0.018901709467172623, -0.019558411091566086, -0.06848980486392975, 0.03380965441465378, -0.01587298884987831, 0.04238608852028847, 0.023343626409769058, 0.015516391023993492, -0.0533587746322155, 0.04694322124123573, -0.04228842258453369, 0.01532965712249279, -0.028677131980657578, 0.06902800500392914, -0.026684220880270004, -0.0030107060447335243, -0.05069728195667267, 0.008859934285283089, -0.004098814446479082, -0.03945283964276314, 0.029090596362948418, -0.0018047199118882418, 0.06976562738418579, -0.051242485642433167, -0.038438402116298676, -0.016587572172284126, -0.013288999907672405, -0.022445039823651314, 0.055941589176654816, -0.04743446409702301, -0.035270027816295624, -0.019298208877444267, -0.007185697555541992, 0.009561662562191486, -0.006971125490963459, -0.06242085620760918, -0.06281578540802002, 0.03287014365196228, 0.0006414157687686384, -0.03242117539048195, -0.06161600351333618, -0.010726121254265308, 0.029884276911616325, 0.04471039026975632, -0.0032472701277583838, -0.00886131078004837, -0.007556069642305374, 0.05749335139989853, 0.016469676047563553, -0.038758255541324615, -0.03547234460711479, 0.033335406333208084, 0.014532512985169888, -0.09844908118247986, -0.050440892577171326, -0.032631173729896545, 0.06434234231710434, -0.06982020288705826, 0.10541646182537079, 0.0667513981461525]'\n",
      "Vecteur brut convo 42: '[-0.0696788802742958, 0.035620078444480896, -0.012612969614565372, 0.057063028216362, 0.02118435874581337, 0.017342081293463707, 0.09837905317544937, -0.05765974149107933, 0.04559655115008354, 0.033859338611364365, 0.04775224253535271, -0.044791046530008316, 0.0021860171109437943, 0.05395342409610748, -0.07344692200422287, 0.03045571781694889, -0.003401381429284811, -0.0013401996111497283, -0.01094053778797388, -0.06967847794294357, -0.03694428130984306, 0.03502126783132553, 0.020589275285601616, 0.04058349132537842, -0.02090192772448063, 0.09528060257434845, 0.057594675570726395, -0.047767408192157745, 0.08665801584720612, -0.09119483083486557, 0.00018964186892844737, 0.09840290248394012, 0.05949927866458893, -0.05331886187195778, -0.003959557972848415, 0.04491102695465088, 0.046202532947063446, 0.043544381856918335, 0.025667112320661545, -0.03431631252169609, -0.008698766119778156, -0.06401095539331436, 0.029906053096055984, 0.0024211229756474495, -0.0057355607859790325, 0.027900107204914093, 0.001560124335810542, 0.053303904831409454, -0.06072605401277542, 0.004484052304178476, -0.02190971188247204, -0.047480031847953796, -0.08912982791662216, 0.010075411759316921, 0.03911272808909416, 0.007513145916163921, -0.0327824205160141, -0.03256404399871826, 0.03154169023036957, -0.02487422339618206, 0.06561186909675598, -0.07705124467611313, -0.053625330328941345, -0.009542516432702541, 0.09606797248125076, 0.051501888781785965, 0.005876150447875261, 0.006092167925089598, 0.017651092261075974, -0.03369465470314026, 0.02962683141231537, 0.08944442868232727, 0.026227643713355064, 0.06905058771371841, 0.10871085524559021, -0.012967073358595371, 0.030374988913536072, -0.007896107621490955, 0.07920707762241364, -0.05377327278256416, -0.017836567014455795, -0.030012942850589752, -0.05119984969496727, 0.07310976833105087, 0.02701382525265217, -0.03446345403790474, -0.02044931799173355, -0.01273366343230009, -0.02910134382545948, -0.02476869896054268, -0.029153741896152496, -0.05565769225358963, -0.05372602492570877, -0.06803964823484421, -0.09097190946340561, 0.012638668529689312, 0.00639291200786829, -0.07539202272891998, 0.0321057103574276, 0.21925131976604462, -0.013746385462582111, 0.049994029104709625, -0.009906276129186153, -0.01968197338283062, -0.03110223263502121, -0.02321936935186386, -0.06588111072778702, -0.05162104219198227, 0.09937821328639984, 0.0017895321361720562, -0.022971805185079575, -0.015779634937644005, 0.007747784722596407, 0.05693351849913597, 0.019291849806904793, 0.01618318073451519, 0.02393142133951187, 0.059709664434194565, -0.0506654754281044, -0.02458086423575878, 0.011074728332459927, 0.005451862700283527, 0.0199004877358675, 0.0017613839590921998, 0.009257977828383446, -0.0004173186607658863, -0.07099296897649765, -5.608563462365423e-33, 0.05839473754167557, -0.028716620057821274, 0.05195334181189537, 0.1148255467414856, 0.014330580830574036, 0.012979904189705849, -0.04146340489387512, -0.068949855864048, -0.029631078243255615, -0.002291044918820262, -0.03538628667593002, 0.06160423532128334, 0.016015738248825073, 0.014283007942140102, 0.042976491153240204, 0.02258988469839096, -0.019881324842572212, 0.06856628507375717, -0.003891560947522521, -0.06742151081562042, -0.051933277398347855, -0.031411994248628616, 0.015521765686571598, -0.04651327431201935, 0.03989396616816521, -0.002530178986489773, -0.0058781118132174015, -0.10792242735624313, 0.034191206097602844, 0.008098537102341652, 0.020213140174746513, 0.044181253761053085, -0.023024115711450577, 0.05525060370564461, -0.007946186698973179, 0.018752658739686012, 0.0009429585770703852, -0.10611390322446823, 0.04202822595834732, -0.01209168042987585, 0.029874060302972794, -0.013002286665141582, 0.00824971403926611, -0.07864049822092056, -0.0010524597018957138, 0.03550218045711517, 0.021278711035847664, 0.03746109455823898, -0.017126483842730522, 0.03754763677716255, -0.04358968511223793, -0.018117286264896393, -0.020530423149466515, -0.07916247099637985, 0.047031428664922714, 0.057207588106393814, -0.04956025257706642, -0.011157501488924026, 0.05001149699091911, 0.05412493646144867, 0.02464614249765873, 0.0646996796131134, -0.021415209397673607, 0.07060329616069794, -0.02172388881444931, 0.07488362491130829, -0.007553589064627886, -0.07609842717647552, 0.05020415410399437, 0.012667685747146606, -0.022010860964655876, 0.04082600399851799, 0.02092740125954151, -0.04046347737312317, 0.011265674605965614, -0.07203862071037292, 0.020500902086496353, -0.02230146713554859, -0.028521083295345306, -0.04128946363925934, -0.10900159180164337, -0.0826275497674942, 0.009989706799387932, -0.0028132374864071608, -0.0683121383190155, -0.013396261259913445, -0.030390799045562744, -0.08005890250205994, -0.060433752834796906, 0.030865533277392387, -0.11147987842559814, 0.049641404300928116, 0.04699331521987915, 0.026453262194991112, -0.005757737439125776, 3.855782366486372e-33, -0.0692981407046318, -0.04934531822800636, 0.05485822260379791, 0.05936160311102867, 0.05149335414171219, -0.05259755626320839, -0.045335572212934494, -0.05449232831597328, -0.0410245843231678, 0.03673600032925606, 0.024364719167351723, -0.004156013950705528, -0.02018391527235508, -0.05775529518723488, 0.00117428635712713, 0.059148356318473816, 0.058036163449287415, -0.013925286009907722, 0.015896115452051163, 0.05825119838118553, -0.0693383440375328, -0.040197812020778656, -0.14730322360992432, -0.045471176505088806, 0.01870875060558319, 0.07047096639871597, 0.01346917636692524, -0.05383724346756935, -0.022990882396697998, 0.027393387630581856, -0.03968378156423569, -0.014027798548340797, -0.02085854485630989, -0.02875552326440811, -0.08804166316986084, 0.10936279594898224, 0.09152009338140488, 0.014722459949553013, -0.013956343755126, -0.009853034280240536, -0.011580446735024452, 0.09093950688838959, -0.06718038767576218, 0.09265673905611038, 0.03375525772571564, -0.07722185552120209, 0.008618257939815521, 0.13737043738365173, 0.009879110381007195, 0.03035718761384487, 0.037436969578266144, 0.013305098749697208, -0.014636020176112652, -0.08364517986774445, -0.00011149311467306688, 0.0928439274430275, -0.0007650009356439114, 0.007869460619986057, 0.04111778363585472, 0.03524245321750641, -0.006087163928896189, -0.05500253289937973, -0.05964285135269165, 0.15908342599868774, -0.022907380014657974, -0.06149819493293762, -0.00510819535702467, 0.09828059375286102, -0.018517054617404938, -0.007942767813801765, 0.033707395195961, 0.04728231206536293, -0.028161050751805305, -0.07207217067480087, -0.01716022565960884, -0.029482416808605194, -0.08663088828325272, -0.011238076724112034, -0.03793339431285858, 0.027153093367815018, -0.03759771212935448, 0.00019237285596318543, 0.01791195571422577, 0.024498993530869484, 0.0031360045541077852, 0.06520865112543106, 0.04420771449804306, 0.028448307886719704, -0.06257633119821548, -0.022681133821606636, -0.05650143697857857, -0.047104060649871826, -0.07102003693580627, -0.028698479756712914, -0.0013210445176810026, -1.2330066745391832e-08, -0.04858890175819397, -0.026002982631325722, 0.027104303240776062, -0.06950649619102478, 0.11526668071746826, 0.06988108903169632, -0.030529998242855072, 0.14711938798427582, -0.06704100221395493, 0.047948647290468216, -0.060626812279224396, 0.03961939737200737, 0.03511117398738861, 0.0929742380976677, 0.07129338383674622, -0.04108337685465813, -0.00316455471329391, -0.06430554389953613, -0.09997440874576569, 0.0313502736389637, 0.054861582815647125, 0.02092459239065647, 0.04410463199019432, 0.03687842935323715, 0.008568307384848595, -0.04049791768193245, 0.035347696393728256, -0.0123657938092947, 0.021264540031552315, 0.0288767758756876, -0.07118865847587585, -0.016503185033798218, 0.025830484926700592, 0.005783743690699339, 0.06609103828668594, 0.0018001736607402563, -0.04927128553390503, -0.048388369381427765, -0.02333621121942997, -0.036082521080970764, -0.029630927368998528, 0.0501602403819561, 0.0018900707364082336, -0.006654341239482164, -0.06729734688997269, -0.024424057453870773, 0.03205164521932602, -0.05353235825896263, -0.03980803117156029, 0.04610833153128624, 0.010971998795866966, -0.02153606154024601, 0.08757835626602173, -0.022964291274547577, 0.09207403659820557, 0.09676319360733032, -0.02084924653172493, -0.001465035486035049, -0.01369103230535984, 0.03759939596056938, 0.15015558898448944, -0.040009401738643646, -0.0165396835654974, 0.015251776203513145]'\n",
      "Vecteur brut convo 42: '[-0.025779137387871742, 0.016027718782424927, -0.027231227606534958, 0.0031425426714122295, -0.048590607941150665, -0.004386059008538723, 0.15196524560451508, 0.13480223715305328, 0.017567668110132217, 0.005231078714132309, -0.042742397636175156, 0.022235207259655, 0.001150689204223454, 0.020567512139678, -0.04188312962651253, -0.004919788800179958, -0.03178809583187103, -0.05379617586731911, -0.08466517180204391, 0.038627445697784424, -0.05276321619749069, 0.08906305581331253, 0.011316846124827862, 0.09086952358484268, -0.05864213407039642, 0.1445358395576477, -0.07386863976716995, 0.009502962231636047, -0.008455654606223106, -0.07030133903026581, 0.0699617937207222, 0.12736274302005768, 0.03993445634841919, 0.008629032410681248, -0.038004208356142044, 0.004552776925265789, -0.049017537385225296, 0.07441001385450363, 0.04447084665298462, -0.0058149234391748905, 0.012934272177517414, -0.10491174459457397, -0.02505137212574482, 0.010043247602880001, -0.0008197159040719271, -0.07309836149215698, -0.03545728698372841, 0.030923567712306976, 0.0765213742852211, 0.04607055336236954, 0.0072637381963431835, -0.028654756024479866, -0.006723889149725437, 0.10537838190793991, 0.004815095104277134, -0.05879312753677368, -0.04241955652832985, 0.05737534165382385, -0.026334695518016815, 0.015075181610882282, 0.04638195037841797, 0.043115705251693726, 0.007369236554950476, 0.02545410953462124, 0.03545539453625679, 0.04021874815225601, -0.020329605787992477, 0.02429831586778164, 0.07975085079669952, 0.011978594586253166, 0.015553563833236694, -0.05816485360264778, 0.054705943912267685, -0.005330887623131275, 0.012630760669708252, -0.04962556064128876, -0.010007884353399277, -0.018442323431372643, 0.029241453856229782, -0.04292724281549454, 0.0706285834312439, -0.011693290434777737, -0.07993782311677933, 0.07217922061681747, 0.03162805363535881, -0.014662198722362518, 0.027783578261733055, 0.016701361164450645, -0.05935569107532501, -0.015668515115976334, 0.00037572800647467375, 0.020998889580368996, -0.011774852871894836, -0.015568445436656475, -0.13051949441432953, -0.029558980837464333, -0.022354615852236748, -0.05927112326025963, -0.09254820644855499, 0.24204277992248535, 0.024075180292129517, 0.08594059199094772, -0.009428245015442371, -0.039896443486213684, 0.0076368930749595165, -0.062210917472839355, 0.014204992912709713, 0.030728282406926155, -0.002875146921724081, -0.02870384231209755, -0.05055950954556465, 0.020756155252456665, 0.006201445125043392, 0.048685938119888306, -0.011437030509114265, 0.08603803813457489, 0.004326459486037493, 0.018003616482019424, -0.009100223891437054, 0.003421319415792823, -0.023442726582288742, 0.002667201915755868, 0.0016558333300054073, -0.015377986244857311, -0.058303091675043106, -0.036397531628608704, 0.011626212857663631, -4.3713130464547483e-33, -0.006698600947856903, -0.028349624946713448, 0.024344436824321747, 0.016812803223729134, -0.010706598870456219, 0.042207784950733185, 0.015425891615450382, -0.04149339720606804, 0.011002269573509693, 0.03881852328777313, -0.06140809878706932, -0.024924682453274727, -0.11028676480054855, 0.1015022024512291, 0.12329578399658203, 0.011768212541937828, -0.05552443861961365, 0.026765506714582443, 0.05594560131430626, -0.013117470778524876, -0.03824358433485031, 0.056123849004507065, -0.06388843804597855, 0.08768755942583084, -0.09600131213665009, 0.018509438261389732, -0.007940859533846378, 0.00792737677693367, 0.06533420085906982, 0.00334766018204391, -0.0018816337687894702, 0.07586552947759628, 0.03868941217660904, -0.05187814310193062, -0.0706256553530693, -0.04680682718753815, -0.0014695706777274609, -0.06765463203191757, 0.023572945967316628, -0.021298984065651894, -0.034678902477025986, 0.031521085649728775, 0.016460834071040154, 0.011075740680098534, 0.055647850036621094, 0.0037176073528826237, -0.060963403433561325, 0.0008388429996557534, -0.09596283733844757, 0.05797155946493149, 0.011607714928686619, -0.057611074298620224, 0.018769029527902603, -0.037004318088293076, -0.04383780062198639, 0.011583293788135052, -0.06041429191827774, -0.027149084955453873, 0.00040805074968375266, 0.028745239600539207, 0.08982302993535995, 0.0974847823381424, -0.06029202789068222, 0.047280535101890564, -0.009982745163142681, -0.05429256707429886, 0.012392165139317513, -0.06401443481445312, 0.011715100146830082, 0.01471120584756136, -0.0814463347196579, -0.0025775518734008074, 0.0247715525329113, 0.05000760033726692, 0.051131486892700195, 0.03497379645705223, 0.04370909184217453, -0.003108259057626128, -0.03188180550932884, -0.005399810150265694, 0.0002761390642262995, -0.10512449592351913, -0.019100451841950417, 0.05728854611515999, -0.08018701523542404, -0.00482898997142911, -0.007312607020139694, -0.0702577531337738, 0.004200064577162266, 0.004541327245533466, -0.09338854253292084, -0.06879786401987076, 0.009833077900111675, 0.01032209675759077, 0.015947725623846054, 3.7359278604505775e-33, 0.03400162234902382, -0.007749052252620459, 0.05367742106318474, 0.06432117521762848, 0.08770117908716202, 0.041341912001371384, -0.004649135284125805, -0.046890974044799805, 0.06786807626485825, 0.06329840421676636, -0.07576082646846771, -0.05545368418097496, 0.08421728014945984, -0.00783317070454359, -0.019695330411195755, -0.030888648703694344, 0.06634200364351273, -0.01623644307255745, -0.03283390775322914, -0.003446403192356229, -0.06559468060731888, 0.03173089772462845, -0.044957589358091354, -0.004063831176608801, -0.014142771251499653, 0.038794297724962234, 0.020468182861804962, -0.04206850379705429, -0.038050659000873566, 0.05233443155884743, 0.016169380396604538, 0.06012227386236191, -0.04384675249457359, -0.021060850471258163, -0.02507259137928486, 0.12420289218425751, 0.009678248316049576, -0.051284726709127426, -0.056163396686315536, -0.07625343650579453, 0.037589121609926224, -0.0029681760352104902, -0.03355620056390762, 0.12423857301473618, -0.007672543171793222, -0.008604413829743862, -0.044687870889902115, 0.07955612987279892, 0.02850436605513096, 0.03316507488489151, -0.03634544834494591, 0.06150692328810692, 0.043267328292131424, -0.0016072827856987715, 0.009332368150353432, -0.01867799274623394, -0.08985277265310287, -0.07232464104890823, -0.026088131591677666, -0.00867186114192009, 0.013401180505752563, 0.05094478651881218, -0.058701567351818085, -0.016222888603806496, -0.043736282736063004, -0.020562734454870224, 0.018212636932730675, 0.03426067903637886, 0.04241017997264862, -0.030094968155026436, 0.11322195082902908, 0.025144172832369804, 0.008418307639658451, 0.09171418100595474, -0.06376121938228607, -0.056209441274404526, -0.1276254951953888, -0.047239020466804504, -0.00487168924883008, -0.09032411873340607, 0.037385448813438416, -0.08389598876237869, -0.01616000384092331, 0.00015934296243358403, -0.11591343581676483, -0.0022467782255262136, 0.048004668205976486, 0.05649968236684799, 0.017733780667185783, -0.00835586991161108, 0.013280731625854969, 0.0016453100834041834, -0.11978205293416977, 0.046689145267009735, -0.011562461964786053, -1.2190580989113187e-08, 0.04158497601747513, -0.0462120920419693, 0.036702416837215424, -0.034547191113233566, -0.0082324780523777, 0.08440941572189331, 0.006878216750919819, 0.03154609352350235, 0.01568765565752983, -0.0008029086166061461, 0.013327288441359997, 0.06174714118242264, -0.0030396338552236557, 0.04385197162628174, 0.001134736929088831, 0.01649676449596882, 0.011519643478095531, 0.04141586646437645, -0.03105776384472847, 0.03615620359778404, -0.07276417315006256, -0.020323902368545532, 0.027749737724661827, 0.035121262073516846, -0.0028811502270400524, -0.04499739035964012, 0.052924055606126785, 0.08289976418018341, 0.010152822360396385, 0.0020058252848684788, 0.04919128865003586, 0.009285706095397472, -0.02623812109231949, 0.005138604901731014, -0.027595123276114464, -0.06353016942739487, 0.027365585789084435, -0.06533874571323395, 0.03336029499769211, -0.01825827918946743, -0.030930738896131516, 0.032163798809051514, 0.014307538978755474, -0.04169194772839546, -0.03076368384063244, -0.04957416281104088, 0.052775174379348755, 0.0297804344445467, -0.00036090335925109684, -0.06481604278087616, 0.005578507669270039, 0.03720784932374954, 0.011228226125240326, -0.027400868013501167, 0.012960558757185936, -0.004759463481605053, -0.00921750720590353, 0.04240143299102783, -0.08709991723299026, -0.07671090215444565, 0.1127539575099945, -0.0012357529485598207, 0.15377230942249298, 0.022025059908628464]'\n",
      "Type de embedding_model : <class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>\n",
      "embedding_model : SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "Is instance of SentenceTransformer? True\n",
      "keyword_rows (after fetch): [(42, 'pharmaceutique'), (42, 'biologique'), (42, 'pharmacien'), (42, 'discovery'), (42, 'assays'), (42, 'scientifique'), (42, 'drug'), (42, 'vitro'), (42, 'fda'), (42, 'potentiel'), (42, 'vivo'), (42, 'identifier'), (42, 'cellule'), (42, 'fonctionnel'), (42, 'impliquer'), (42, 'cible'), (42, 'processus'), (42, 'identification'), (42, 'organique'), (42, 'antiviral'), (42, 'maladie'), (42, 'interagir'), (42, 'cellulaire'), (42, 'informatique'), (42, 'complexe')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorcarre/Code/Projects/llm-memorization/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (512) is larger than the maximum possible length (257). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tes discussions avec l'utilisateur t'ont amené à répondre à cette question : 'Comment faire du \"drug discovery\" dans le secteur pharmaceutique ?'\n",
      "Ces intéractions vous ont amené à discuter de ces sujets :\n",
      "- Le processus de drug discovery est un des plus importants et coûteux dans le secteur pharmaceutique. Voici les étapes clés du processus : 1. Identification des cibles : La première étape consiste à identifier les protéines ou les mécanismes cellulaires impliqués dans une maladie donnée ; ensuite, les scientifiques développent des molécules qui interagissent avec la cible et modulent son activité (chimiques, biologiques, cytogènes, etc). Synthèse de composés : Les molécules conçues sont then synthétisées et testées en laboratoire pour déterminer leur efficacité et leur sécurité. Approbation réglementaire : Si un médicament réussit ses essais cliniques, l'entreprise qui le développe doit soumettre une demande de ses filiales à une agence réglementaire, telle que la FDA en Europe ou l'Agence européenne de l'assurance maladie (Agence de la santé) en Europe (Agence des médicaments ou des produits de la sécurité du médicament) a une autorisation de la FDA pour l'agence du médicament (ANSA) pour les États-Unis ou les autorités sanitaires (FeMA) pour la FDA (États-Unis) pour le produit pharmaceutique) pour une autorisation d'utiliser l'a approuvé pour la commercialisation ou pour la mise sur l'ensemble de la population ou des patients pour la reproduction des patients.\n",
      "Réponds maintenant à cette question, dans le contexte de vos discussions précédentes : Comment la photocatalyse rédox est actuellement appliquée en \"drug discovery\" du secteur pharmaceutique ?\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === TEST RAPIDE NO GUI ===\n",
    "question = 'Comment la photocatalyse rédox est actuellement appliquée en \"drug discovery\" du secteur pharmaceutique ?'\n",
    "context = get_relevant_context(question)\n",
    "prompt = generate_prompt_paragraph(context, question)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f22605c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array(vec[\u001b[32m0\u001b[39m], dtype=\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m test_text = \u001b[33m\"\u001b[39m\u001b[33mTest sentence for embedding\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_vector_for_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m)\u001b[49m.shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mget_vector_for_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_vector_for_text\u001b[39m(text):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     vec = \u001b[43membedding_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array(vec[\u001b[32m0\u001b[39m], dtype=\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Projects/llm-memorization/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Projects/llm-memorization/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Projects/llm-memorization/.venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:758\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m    756\u001b[39m     module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m    757\u001b[39m     module_kwargs = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Projects/llm-memorization/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Projects/llm-memorization/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Projects/llm-memorization/.venv/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py:438\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch.Tensor], **kwargs) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch.Tensor]:\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m     trans_features = {\n\u001b[32m    437\u001b[39m         key: value\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m()\n\u001b[32m    439\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minputs_embeds\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    440\u001b[39m     }\n\u001b[32m    442\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.auto_model(**trans_features, **kwargs, return_dict=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    443\u001b[39m     token_embeddings = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_vector_for_text(text):\n",
    "    vec = embedding_model([text])\n",
    "    return np.array(vec[0], dtype='float32')\n",
    "\n",
    "test_text = \"Test sentence for embedding\"\n",
    "print(get_vector_for_text(test_text).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4535a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === INTERFACE TKINTER ===\n",
    "\n",
    "def update_status(message, error=False, success=False):\n",
    "    \"\"\"Met à jour le label de statut avec style approprié\"\"\"\n",
    "    label_status.config(text=message)\n",
    "    if error:\n",
    "        label_status.config(foreground='#ff6b6b')\n",
    "    elif success:\n",
    "        label_status.config(foreground='#599258')\n",
    "    else:\n",
    "        label_status.config(foreground='white')\n",
    "\n",
    "def open_github(event):\n",
    "    webbrowser.open_new(\"https://github.com/victorcarre6\")\n",
    "\n",
    "def show_help():\n",
    "    help_text = (\n",
    "        \"LLM Memorization and Prompt Enhancer — Aide\\n\\n\"\n",
    "        \"• Synchroniser les conversations : ajoute les nouveaux échanges depuis LM Studio à la base de données.\\n\\n\"\n",
    "        \"• Générer prompt : extrait les mots-clés de votre question, cherche des conversations similaires dans votre base SQL, puis compresse les informations avec un LLM local.\\n\\n\"\n",
    "        \"Le prompt final est affiché puis automatiquement copié dans votre presse-papier !\\n\\n\"\n",
    "        \"Pour en savoir plus, obtenir plus d'informations à propos d'un éventuel bloquage des scripts, ou me contacter, visitez : github.com/victorcarre6/llm-memorization\"\n",
    "    )\n",
    "    help_window = tk.Toplevel(root)\n",
    "    help_window.title(\"Aide\")\n",
    "    help_window.geometry(\"500x300\")\n",
    "    help_window.configure(bg=\"#323232\")\n",
    "\n",
    "    text_widget = tk.Text(help_window, wrap=tk.WORD, font=(\"Segoe UI\", 8))\n",
    "    text_widget.insert(tk.END, help_text)\n",
    "    text_widget.config(state=tk.DISABLED)\n",
    "    text_widget.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "\n",
    "    ok_button = tk.Button(help_window, text=\"Fermer\", command=help_window.destroy)\n",
    "    ok_button.pack(pady=10)\n",
    "\n",
    "# === CONFIGURATION DE L'INTERFACE ===\n",
    "root.title(\"LLM Memorization and Prompt Enhancer\")\n",
    "root.geometry(\"1000x325\")\n",
    "root.configure(bg=\"#323232\")\n",
    "\n",
    "# Style global unique\n",
    "style = ttk.Style(root)\n",
    "style.theme_use('clam')\n",
    "\n",
    "# Configuration du style\n",
    "style_config = {\n",
    "    'Green.TButton': {\n",
    "        'background': '#599258',\n",
    "        'foreground': 'white',\n",
    "        'font': ('Segoe UI', 11),\n",
    "        'padding': 4\n",
    "    },\n",
    "    'Bottom.TButton': {\n",
    "        'background': '#599258',\n",
    "        'foreground': 'white',\n",
    "        'font': ('Segoe UI', 9),\n",
    "        'padding': 2\n",
    "    },\n",
    "    'Blue.TLabel': {\n",
    "        'background': '#323232',\n",
    "        'foreground': '#599258',\n",
    "        'font': ('Segoe UI', 8, 'italic underline'),\n",
    "        'padding': 0\n",
    "    },\n",
    "    'TLabel': {\n",
    "        'background': '#323232',\n",
    "        'foreground': 'white',\n",
    "        'font': ('Segoe UI', 11)\n",
    "    },\n",
    "    'TEntry': {\n",
    "        'fieldbackground': '#FDF6EE',\n",
    "        'foreground': 'black',\n",
    "        'font': ('Segoe UI', 11)\n",
    "    },\n",
    "    'TFrame': {\n",
    "        'background': '#323232'\n",
    "    },\n",
    "    'Status.TLabel': {\n",
    "        'background': '#323232',\n",
    "        'font': ('Segoe UI', 11)\n",
    "    },\n",
    "    'TNotebook': {\n",
    "        'background': '#323232',\n",
    "        'borderwidth': 0\n",
    "    },\n",
    "    'TNotebook.Tab': {\n",
    "        'background': '#2a2a2a',\n",
    "        'foreground': 'white',\n",
    "        'padding': (10, 4)\n",
    "    },\n",
    "    'Custom.Treeview': {\n",
    "        'background': '#2a2a2a',\n",
    "        'foreground': 'white',\n",
    "        'fieldbackground': '#2a2a2a',\n",
    "        'font': ('Segoe UI', 10),\n",
    "        'bordercolor': '#323232',\n",
    "        'borderwidth': 0,\n",
    "    },\n",
    "    'Custom.Treeview.Heading': {\n",
    "        'background': '#323232',\n",
    "        'foreground': '#599258',\n",
    "        'font': ('Segoe UI', 11, 'bold'),\n",
    "        'relief': 'flat'\n",
    "    }\n",
    "}\n",
    "\n",
    "for style_name, app_config in style_config.items():\n",
    "    style.configure(style_name, **app_config)\n",
    "\n",
    "style.map('Green.TButton',\n",
    "          background=[('active', '#457a3a'), ('pressed', '#2e4a20')],\n",
    "          foreground=[('disabled', '#d9d9d9')])\n",
    "\n",
    "style.map(\"TNotebook.Tab\",\n",
    "          background=[(\"selected\", \"#323232\"), (\"active\", \"#2a2a2a\")],\n",
    "          foreground=[(\"selected\", \"white\"), (\"active\", \"white\")])\n",
    "\n",
    "\n",
    "style.map('Bottom.TButton',\n",
    "          background=[('active', '#457a3a'), ('pressed', '#2e4a20')],\n",
    "          foreground=[('disabled', '#d9d9d9')])\n",
    "\n",
    "# Widgets principaux\n",
    "main_frame = ttk.Frame(root, style='TFrame')\n",
    "main_frame.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "\n",
    "# Section question - Centrée\n",
    "question_header = ttk.Frame(main_frame, style='TFrame')\n",
    "question_header.pack(fill='x', pady=(0, 1))\n",
    "ttk.Label(question_header, text=\"Poser la question :\").pack(expand=True)\n",
    "\n",
    "question_frame = tk.Frame(main_frame, bg=\"#323232\")\n",
    "question_frame.pack(pady=(0, 5), fill='x', expand=True)\n",
    "\n",
    "entry_question = tk.Text(question_frame, height=4, width=80, wrap=\"word\", font=('Segoe UI', 11))\n",
    "entry_question.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "\n",
    "# Configuration du style pour la scrollbar\n",
    "style = ttk.Style()\n",
    "style.configure(\"Vertical.TScrollbar\",\n",
    "    troughcolor='#FDF6EE',\n",
    "    background='#C0C0C0',\n",
    "    darkcolor='#C0C0C0',\n",
    "    lightcolor='#C0C0C0',\n",
    "    bordercolor='#FDF6EE',\n",
    "    arrowcolor='black',\n",
    "    relief='flat')\n",
    "\n",
    "scrollbar = ttk.Scrollbar(\n",
    "    question_frame,\n",
    "    orient=\"vertical\",\n",
    "    command=entry_question.yview,\n",
    "    style=\"Vertical.TScrollbar\"  # Application du style\n",
    ")\n",
    "scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "entry_question.config(yscrollcommand=scrollbar.set)\n",
    "entry_question.bind(\"<Return>\", lambda event: on_ask())\n",
    "\n",
    "# Frame horizontale principale\n",
    "control_frame = ttk.Frame(main_frame, style='TFrame')\n",
    "control_frame.pack(fill='x', pady=(0, 10), padx=5)\n",
    "\n",
    "# Sliders\n",
    "slider_keywords_frame = ttk.Frame(control_frame, style='TFrame')\n",
    "slider_keywords_frame.grid(row=0, column=0, sticky='w')\n",
    "\n",
    "label_keyword_count = ttk.Label(slider_keywords_frame, text=f\"Nombre de mots-clés : {keyword_count_var.get()}\", style='TLabel')\n",
    "label_keyword_count.pack(anchor='w')\n",
    "\n",
    "slider_keywords = ttk.Scale(\n",
    "    slider_keywords_frame,\n",
    "    from_=1,\n",
    "    to=15,\n",
    "    orient=\"horizontal\",\n",
    "    variable=keyword_count_var,\n",
    "    length=180,\n",
    "    command=lambda val: label_keyword_count.config(text=f\"Nombre de mots-clés : {int(float(val))}\")\n",
    ")\n",
    "slider_keywords.pack(anchor='w')\n",
    "\n",
    "slider_context_frame = ttk.Frame(control_frame, style='TFrame')\n",
    "slider_context_frame.grid(row=0, column=1, padx=20, sticky='w')\n",
    "\n",
    "label_contexts_count = ttk.Label(slider_context_frame, text=f\"Nombre de contextes : {context_count_var.get()}\", style='TLabel')\n",
    "label_contexts_count.pack(anchor='w')\n",
    "\n",
    "slider_contexts = ttk.Scale(\n",
    "    slider_context_frame,\n",
    "    from_=1,\n",
    "    to=5,\n",
    "    orient=tk.HORIZONTAL,\n",
    "    variable=context_count_var,\n",
    "    length=170,\n",
    "    command=lambda val: label_contexts_count.config(text=f\"Nombre de contextes : {int(float(val))}\")\n",
    ")\n",
    "slider_contexts.pack(anchor='w')\n",
    "\n",
    "# Boutons synchronisation et percuteur\n",
    "button_frame = ttk.Frame(control_frame, style='TFrame')\n",
    "button_frame.grid(row=0, column=2, sticky='e')\n",
    "\n",
    "sync_button = ttk.Button(button_frame, text=\"Synchroniser les conversations\", \n",
    "                         command=sync_conversations, style='Green.TButton')\n",
    "sync_button.pack(side='left', padx=5)\n",
    "\n",
    "btn_ask = ttk.Button(button_frame, text=\"Générer prompt\", command=on_ask, style='Green.TButton')\n",
    "btn_ask.pack(side='left', padx=5)\n",
    "control_frame.grid_columnconfigure(2, weight=1)\n",
    "\n",
    "# Zone de sortie étendable\n",
    "output_expanded = tk.BooleanVar(value=False)\n",
    "\n",
    "def toggle_output():\n",
    "    \"\"\"Basculer l'affichage de la zone de sortie et ajuster la taille de la fenêtre\"\"\"\n",
    "    if output_expanded.get():\n",
    "        text_output.pack_forget()\n",
    "        toggle_btn.config(text=\"▼ Afficher le résultat\")\n",
    "        output_expanded.set(False)\n",
    "        root.geometry(\"1000x325\")\n",
    "    else:\n",
    "        text_output.pack(fill=tk.BOTH, expand=True, pady=(5, 0))\n",
    "        toggle_btn.config(text=\"▲ Masquer le résultat\")\n",
    "        output_expanded.set(True)\n",
    "        root.geometry(\"1000x750\")\n",
    "\n",
    "output_frame = ttk.Frame(main_frame, style='TFrame')\n",
    "output_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 10))\n",
    "\n",
    "# Bouton pour étendre/cacher\n",
    "toggle_btn = ttk.Button(\n",
    "    output_frame,\n",
    "    text=\"▼ Afficher le résultat\",\n",
    "    command=toggle_output,\n",
    "    style='Green.TButton'  # Utilise le même style que tes autres boutons\n",
    ")\n",
    "toggle_btn.pack(fill=tk.X, pady=(0, 5))\n",
    "\n",
    "text_output = scrolledtext.ScrolledText(\n",
    "    output_frame, \n",
    "    width=100, \n",
    "    height=20,\n",
    "    font=('Segoe UI', 11), \n",
    "    wrap=tk.WORD, \n",
    "    bg=\"#FDF6EE\", \n",
    "    fg=\"black\", \n",
    "    insertbackground=\"black\"\n",
    ")\n",
    "\n",
    "def show_infos():\n",
    "    info_window = tk.Toplevel(root)\n",
    "    info_window.title(\"Détails sur le prompt généré\")\n",
    "    info_window.geometry(\"750x725\")\n",
    "    container = tk.Frame(info_window, bg=\"#323232\")\n",
    "    container.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    info_window.transient(root)\n",
    "    info_window.grab_set()\n",
    "\n",
    "    question = entry_question.get(\"1.0\", tk.END).strip()\n",
    "    if not question:\n",
    "        update_status(\"⚠️ Posez une question d'abord.\", error=True)\n",
    "        return\n",
    "\n",
    "    keywords = extract_keywords(question)\n",
    "    if not keywords:\n",
    "        update_status(\"⚠️ Aucun mot-clé extrait.\", error=True)\n",
    "        return\n",
    "\n",
    "    filtered_context = get_relevant_context(question, limit=5)\n",
    "    if not filtered_context:\n",
    "        update_status(\"⚠️ Aucun contexte trouvé.\", error=True)\n",
    "        return\n",
    "\n",
    "    notebook = ttk.Notebook(container, style=\"TNotebook\")\n",
    "    notebook.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "\n",
    "    single_tab = ttk.Frame(notebook, style=\"TFrame\")\n",
    "    notebook.add(single_tab, text=\"Mots-clés & Stats\")\n",
    "\n",
    "        # Calcul des fréquences dans les contextes\n",
    "    full_text_context = \" \".join(user_input + \" \" + llm_output for user_input, llm_output, _, _ in filtered_context).lower()\n",
    "    token_list = re.findall(r'\\b[a-zA-Z\\-]{3,}\\b', full_text_context)\n",
    "\n",
    "    word_counts = {}\n",
    "    for kw, _, _ in keywords:\n",
    "        count = token_list.count(kw.lower())\n",
    "        word_counts[kw] = count\n",
    "\n",
    "    # --- Histogramme ---\n",
    "    fig, ax = plt.subplots(figsize=(6, 4), dpi=100)\n",
    "    bars = ax.bar(word_counts.keys(), word_counts.values(), color='#599258')\n",
    "\n",
    "    ax.set_facecolor(\"#323232\")\n",
    "    fig.patch.set_facecolor(\"#323232\")\n",
    "    ax.set_title(\"Fréquence des mots-clés dans les contextes\", color=\"white\", fontsize=10)\n",
    "    ax.set_ylabel(\"Occurrences\", color=\"white\", fontsize=10)\n",
    "    ax.tick_params(axis='x', labelrotation=45, colors=\"white\", labelsize=10)\n",
    "    ax.tick_params(axis='y', colors=\"white\", labelsize=10)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('white')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, master=single_tab)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=False, padx=10, pady=(10, 0))\n",
    "\n",
    "    # --- Tableau Treeview ---\n",
    "    cols = ('Mot-clé', 'Poids', 'Occurrences dans contextes')\n",
    "    tree = ttk.Treeview(single_tab, columns=cols, show='headings', height=10, style='Custom.Treeview')\n",
    "    for col in cols:\n",
    "        tree.heading(col, text=col)\n",
    "        tree.column(col, width=150)\n",
    "    tree.pack(expand=False, fill='both', padx=10, pady=(10, 0))\n",
    "\n",
    "    tree.tag_configure('oddrow', background='#2a2a2a')\n",
    "    tree.tag_configure('evenrow', background='#383838')\n",
    "\n",
    "    for i, (kw, weight, _) in enumerate(keywords):\n",
    "        freq_in_context = word_counts.get(kw, 0)\n",
    "        tag = 'evenrow' if i % 2 == 0 else 'oddrow'\n",
    "        tree.insert('', tk.END, values=(kw, f\"{weight:.3f}\", freq_in_context), tags=(tag,))\n",
    "\n",
    "    btn_copy = ttk.Button(single_tab, text=\"Copier mots-clés\", command=lambda: (\n",
    "        root.clipboard_clear(),\n",
    "        root.clipboard_append(\",\".join([kw for kw, _, _ in keywords])),\n",
    "    ), style='Bottom.TButton')\n",
    "    btn_copy.pack(pady=10)\n",
    "\n",
    "    # === Onglet 2 : Contexte ===\n",
    "    context_frame = ttk.Frame(notebook, style=\"TFrame\")\n",
    "    notebook.add(context_frame, text=\"Contextes\")\n",
    "\n",
    "    lbl_container = tk.Frame(context_frame, bg=\"#323232\")\n",
    "    lbl_container.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    tk.Label(lbl_container, text=\"Questions contextuelles :\", fg=\"white\", bg=\"#323232\", font=(\"Segoe UI\", 10, \"bold\")).pack(pady=5)\n",
    "    tk.Label(lbl_container,\n",
    "             text=\"Légende :\\n- 1 mot clef : rouge\\n- 2 ou 3 : orange\\n- >3 : vert\",\n",
    "             fg=\"white\", bg=\"#323232\", justify=\"left\", wraplength=700, font=(\"Segoe UI\", 8, \"italic\")).pack(anchor=\"w\", padx=10, pady=(0, 10))\n",
    "\n",
    "    for item in filtered_context:\n",
    "        q_text = item[0]\n",
    "        extracted = set(kw for kw, _, _ in extract_keywords(q_text))\n",
    "        base_keywords = set(kw for kw, _, _ in keywords)\n",
    "        shared = len(extracted & base_keywords)\n",
    "        color = \"#ff6b6b\" if shared <= 1 else \"#ffb347\" if shared <= 3 else \"#7CFC00\"\n",
    "        tk.Label(\n",
    "            lbl_container,\n",
    "            text=q_text[:100] + (\"...\" if len(q_text) > 100 else \"\"),\n",
    "            fg=color, bg=\"#323232\", wraplength=700\n",
    "        ).pack(anchor=\"w\", padx=10)\n",
    "\n",
    "    # === Onglet 3 : Carte mentale ===\n",
    "    mindmap_frame = ttk.Frame(notebook, style=\"TFrame\")\n",
    "    notebook.add(mindmap_frame, text=\"Carte mentale\")\n",
    "\n",
    "    canvas = tk.Canvas(mindmap_frame, bg=\"#323232\", highlightthickness=0)\n",
    "    canvas.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    questions_list = [item[0] for item in filtered_context]\n",
    "    keywords_per_question = [set(kw for kw, _, _ in extract_keywords(q)) for q in questions_list]\n",
    "\n",
    "    import math\n",
    "    n = len(questions_list)\n",
    "    center_x, center_y = 350, 300\n",
    "    radius = 250\n",
    "    nodes_positions = []\n",
    "\n",
    "    for i in range(n):\n",
    "        angle = 2 * math.pi * i / n\n",
    "        x = center_x + radius * math.cos(angle)\n",
    "        y = center_y + radius * math.sin(angle)\n",
    "        nodes_positions.append((x, y))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if keywords_per_question[i] & keywords_per_question[j]:\n",
    "                x1, y1 = nodes_positions[i]\n",
    "                x2, y2 = nodes_positions[j]\n",
    "                canvas.create_line(x1, y1, x2, y2, fill=\"#7CFC00\", width=1)\n",
    "\n",
    "    radius_node = 15\n",
    "    _tooltip = None\n",
    "\n",
    "    def show_tooltip(event, text):\n",
    "        nonlocal _tooltip\n",
    "        if _tooltip:\n",
    "            canvas.delete(_tooltip)\n",
    "            _tooltip = None\n",
    "        x, y = event.x + 10, event.y + 10\n",
    "        _tooltip = canvas.create_text(x, y, text=text, anchor=\"nw\", fill=\"white\", font=(\"Segoe UI\", 9), width=300, tags=\"tooltip\")\n",
    "\n",
    "    def hide_tooltip(event):\n",
    "        nonlocal _tooltip\n",
    "        if _tooltip:\n",
    "            canvas.delete(_tooltip)\n",
    "            _tooltip = None\n",
    "\n",
    "    for i, (x, y) in enumerate(nodes_positions):\n",
    "        node = canvas.create_oval(x - radius_node, y - radius_node, x + radius_node, y + radius_node, fill=\"#599258\", outline=\"\")\n",
    "        canvas.tag_bind(node, \"<Enter>\", lambda e, q=questions_list[i]: show_tooltip(e, q))\n",
    "        canvas.tag_bind(node, \"<Leave>\", hide_tooltip)\n",
    "\n",
    "# Barre de statut ET boutons - Frame horizontal unifié\n",
    "status_buttons_frame = ttk.Frame(main_frame, style='TFrame')\n",
    "status_buttons_frame.pack(fill=tk.X, pady=(5, 2))\n",
    "\n",
    "# Statut à gauche\n",
    "label_status = ttk.Label(\n",
    "    status_buttons_frame,\n",
    "    text=\"Prêt\",\n",
    "    style='Status.TLabel',\n",
    "    foreground='white',\n",
    "    anchor='w'  # Alignement à gauche plus naturel\n",
    ")\n",
    "label_status.pack(side=tk.LEFT, anchor='w')\n",
    "\n",
    "# Boutons à droite - dans le même frame horizontal\n",
    "right_buttons = ttk.Frame(status_buttons_frame, style='TFrame')\n",
    "right_buttons.pack(side=tk.RIGHT, anchor='e')\n",
    "\n",
    "btn_info = ttk.Button(right_buttons, text=\"Détails\", style='Bottom.TButton', command=show_infos, width=8)\n",
    "btn_info.pack(side=tk.TOP, pady=(0, 3))\n",
    "\n",
    "btn_help = ttk.Button(right_buttons, text=\"Aide\", style='Bottom.TButton', command=show_help, width=8)\n",
    "btn_help.pack(side=tk.TOP)\n",
    "\n",
    "# Footer - inchangé\n",
    "footer_frame = ttk.Frame(root, style='TFrame')\n",
    "footer_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=(0, 5))\n",
    "\n",
    "dev_label = ttk.Label(footer_frame, text=\"Développé par Victor Carré —\", style='TLabel', font=('Segoe UI', 8))\n",
    "dev_label.pack(side=tk.LEFT)\n",
    "\n",
    "github_link = ttk.Label(footer_frame, text=\"GitHub\", style='Blue.TLabel', cursor=\"hand2\")\n",
    "github_link.pack(side=tk.LEFT)\n",
    "github_link.bind(\"<Button-1>\", open_github)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa4815",
   "metadata": {},
   "source": [
    "# Idées\n",
    "\n",
    "- Mettre le choix du modèle dans le fichier `config.json`\n",
    "- Remplacer le hashage par du MD5\n",
    "- Colorer les contextes en fonction du nombre de keywords communs\n",
    "- Affichage d'un nuage de mots dans une seconde fenêtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d81295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"La photocatalyse est une méthode qui permet d'activer des réactions chimiques via la lumière. Elle est utilisée notamment dans l'industrie pharmaceutique pour faire des économies d'énergie et d'argent, selon une étude de la revue scientifique Plos Medecine, citée par le quotidien américain The Lancet dans son rapport annuel publié mardi.Le site de l'institut.\"}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "test = \"La photocatalyse est une méthode qui permet d'activer des réactions chimiques via la lumière. Elle est utilisée dans l'industrie pharmaceutique pour...\"\n",
    "output = summarizer(test, max_length=150, min_length=75)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d639a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
